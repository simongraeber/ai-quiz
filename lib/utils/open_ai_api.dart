import 'dart:typed_data';
import 'package:http/http.dart' as http;
import 'package:quiz/utils/question.dart';
import 'dart:convert';
import 'team.dart';
import 'package:flutter_gen/gen_l10n/l10n.dart';

/// this singleton class is used to communicate with the OpenAI API
/// it holes the API Key and is used to generate images and questions
class OpenAIApi {
  static final OpenAIApi _singleton = OpenAIApi._internal();

  // the API key for the OpenAI API
  String? _aPIKey;

  factory OpenAIApi() {
    return _singleton;
  }

  OpenAIApi._internal();

  get aPIKey => _aPIKey;

  /// sets the API key for the OpenAI API
  /// [key] the API key
  Future<void> setAPIKey(String key) async {
    _aPIKey = key;
    try{
      await _getText("say hi", 10); // test if the key is valid
    } catch(e){
      _aPIKey = null;
      rethrow;
    }
    return;
  }

  /// returns a funny image for a team with the name [name]
  /// the image is generated by the OpenAI API
  /// image will be PNG 512x512
  Future<ImageWithDescription> getTeamImage(String name) async {
    String prompt =
        'Briefly describe a funny profile picture for a team.'
        '\nThe team is could "$nameâ€œ. Describe the picture in English. You must not describe any text like on Signs or shirts, use icons if needed. Also avoid using names of persons just describe them if needed.'
        '\n\nImage description: A Image';

    // get a description for a funny image
    String imageText = "A image${await _getText(prompt, 200)}";

    // get the image
    Uint8List image = await _getImage(imageText, 512);

    // return the image and the description
    return ImageWithDescription(image, imageText);
  }

  /// explain way the answer is the only correct answer
  /// [question] the question to explain
  /// [context] the context for the localizations
  /// returns a string with the explanation for the answer and why it is the only correct answer
  Future<String> getExplanation(Question question, context) async {
    String prompt = AppLocalizations.of(context)!.explainQuestionPrompt(question.getRealAnswer(context).toString(), question.getWrongAnswers(), question.questionText);

    String explanation = await _getText(prompt, 500);
    return explanation;
  }

  /// Generates a question from the OpenAI API
  /// [category] is the category of the question which can be any string
  /// [difficulty] is the difficulty of the question 1 to 5
  /// Returns a Question object
  /// throws an error if the question could not be generated or is in the wrong format
  Future<Question> getQuestion(String category, String difficulty, context) async {

    // get the question prompt using the localizations to get the correct language
    String prompt = AppLocalizations.of(context)!.getQuestionPrompt(category, difficulty);

    // get the question text in the correct language and format
    String questionAndAnswerText = "";
    try{
      questionAndAnswerText = await _getText(prompt, 300);
      questionAndAnswerText = questionAndAnswerText.trim();
    } catch(e){
      return Future.error(e.toString());
    }
    try{ // try to parse the question
      List<String> lines = questionAndAnswerText.split("\n");
      String questionText = lines[0].split(":")[1].trim();
      String answerText01 = lines[1].split(":")[1].trim();
      String answerText02 = lines[2].split(":")[1].trim();
      String answerText03 = lines[3].split(":")[1].trim();
      String answerText04 = lines[4].split(":")[1].trim();
      int correctAnswer = int.parse(lines[5].split(":")[1].trim().substring(1));
      return Question(questionText, answerText01, answerText02, answerText03,
          answerText04, correctAnswer);
    } catch(e){
      return Future.error("The OpenAI API returned an invalid question. Please try again.");

    }

  }

  /// Generates an image for the question
  /// [question] is the question for which the image should be generated
  /// [category] is the category of the question
  ///  returns a Uint8List with the png image 512x512
  Future<Uint8List> getQuestionImage(
      Future<Question> question, String category) async {
    Question q = await question;

    String prompt =
        '\nBriefly describe a charcoal drawing for a Quiz show based on this question in english.'
        '\nthe category for this question is: "$category" and the question is: "${q.questionText}"'
        "Do not spoil the answer in the image. There is no text in the drawing."
        "\n\nImage description: A charcoal drawing of";

    String imageText = "A charcoal drawing of ${await _getText(prompt, 100)}";
    Uint8List image = await _getImage(imageText, 512);
    return image;
  }

  /// Generates an image with the teams on a podium
  /// [image] is the image of the podium must be 1024x1024 pixels and a png with RGBA
  /// [mask] is the mask 1024x1024 pixels and a png with RGBA
  /// [teamNames] is a list of the names of the teams in sorted order first the first place team
  /// [teamDescription] is a list of the descriptions of the teams in sorted order first the first place team
  /// returns a Uint8List with the png image 1024x1024
  Future<Uint8List> getCompletedPodiumImage(Uint8List image, Uint8List mask) async {

    String prompt =  "\nBriefly describe a hilarious image from an award ceremony. Describe something crazy or funny that is happening above and behind the teams."
                    "\n\nImage description: A image of an award ceremony.";

    String imageText = "A image of an award ceremony. ${await _getText(prompt, 200)}";

    Uint8List completedImage =
        await _getCompletedImage(image, mask, imageText, 1024);
    return completedImage;
  }

  /// used to complete an existing image based on a prompt and a mask
  /// it uses the OpenAI API Image edits endpoint see https://platform.openai.com/docs/guides/images/usage
  /// [size] is the size of the image in pixels must be 256, 512, or 1024.
  /// [prompt] is the text that describes the entire image
  /// [image] is the image to be completed in base64 format PNG in RGBA format
  /// [mask] is the mask to be used in base64 format PNG in RGBA format the transparent pixels are the pixels that will be completed
  Future<Uint8List> _getCompletedImage(
      Uint8List image, Uint8List mask, String prompt, int size) async {
    final request = http.MultipartRequest(
      'POST',
      Uri.parse('https://api.openai.com/v1/images/edits'),
    )
      ..headers["Authorization"] = 'Bearer $_aPIKey'
      ..fields.addAll({
        'size': '${size}x$size',
        'n': '1', // just  get one image
        'prompt': prompt,
        'response_format': 'b64_json' // return the image as base64
      })
      ..files.addAll([
        http.MultipartFile.fromBytes(
          'image',
          image,
          filename: 'image.png',
        ),
        http.MultipartFile.fromBytes(
          'mask',
          mask,
          filename: 'mask.png',
        ),
      ]);
    final response = await http.Response.fromStream(await request.send());

    if (response.statusCode == 201 || response.statusCode == 200) {
      Map<String, dynamic> data = jsonDecode(response.body);
      var b64 = data["data"][0]["b64_json"];
      return const Base64Codec().decode(b64);
    } else {
      throw Exception(['http.post error', response.statusCode, response.body]);
    }
  }

  /// Generates a Image with the OpenAI API Image generations endpoint see https://platform.openai.com/docs/guides/images/usage
  /// based on the description in [prompt]
  /// [size] is the size of the image in pixels must be 256, 512, or 1024.
  Future<Uint8List> _getImage(String prompt, int size) async {
    http.Response response = await http.post(
      Uri.parse('https://api.openai.com/v1/images/generations'),
      headers: <String, String>{
        'Authorization': 'Bearer $_aPIKey',
        'Content-Type': 'application/json',
      },
      body: jsonEncode(<String, dynamic>{
        'size': '${size}x$size',
        'n': 1, // just  get one image
        'prompt': prompt,
        'response_format': 'b64_json' // return the image as base64
      }),
    );
    if (response.statusCode == 201 || response.statusCode == 200) {
      Map<String, dynamic> data = jsonDecode(response.body);
      var b64 = data["data"][0]["b64_json"];
      return const Base64Codec().decode(b64);
    } else {
      throw Exception(['http.post error', response.statusCode, response.body]);
    }
  }

  /// Generates text from the OpenAI API Text completions endpoint see https://platform.openai.com/docs/guides/completion/
  /// using the given [prompt] limit of [maxTokens] controls the maximum length of the generated text
  /// [model] is the model to be used see https://platform.openai.com/docs/models/gpt-3 by default it is text-davinci-003
  /// the [temperature] controls the randomness of the generated text by default it is 0.4
  /// returns the generated text
  Future<String> _getText(String prompt, int maxTokens, [String? model, double? temperature]) async {
    http.Response response = await http.post(
      Uri.parse('https://api.openai.com/v1/completions'),
      headers: <String, String>{
        'Authorization': 'Bearer $_aPIKey',
        'Content-Type': 'application/json; charset=utf-8',
      },
      body: jsonEncode(<String, dynamic>{
        'model': model ?? 'text-davinci-003',
        'prompt': prompt,
        'max_tokens': maxTokens,
        'temperature': temperature ?? 0.4,
      }),
    );
    if (response.statusCode == 201 || response.statusCode == 200) {
      String body = utf8.decode(response.bodyBytes);
      Map<String, dynamic> data = jsonDecode(body);
      return data["choices"][0]["text"].trim();
    } else {
      throw Exception(['http.post error', response.statusCode, response.body]);
    }
  }
}
